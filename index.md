---
layout: default
description: I'm Rachit Bansal and I work on Natural Language Processing. More details inside!
---

<!-- (comment) the image below can be found in img folder of this very project-->
![i_am_rachit](./img/people/me.png){: style="float: right; margin: 0px 20px; width: 180px;" name="fox"}


I am Rachit Bansal, a pre-doctoral researcher at Google Research India. I am broadly interested in making language models useful, controllable, and accessible. I am also interested in interpretability and analysis. Previously, I was an undergraduate student at the Delhi Technological University.

Over the past few years, I walked my first baby steps as a researcher owing to some wonderful people and collaborations. I pursued my bachelor's thesis research with [Prof. Yonatan Belinkov](http://www.cs.technion.ac.il/~belinkov/) at the Technion in Israel. There I had a great time studying how [intrinsic proprties of a neural network](https://rachitbansal.github.io/information-measures) is informative of generalization behaviours. Before that, I was a research intern at [Adobe](https://research.adobe.com/)'s Media and Data Science Research Lab, where I worked on [commonsense reasoning for large language models](https://aclanthology.org/2022.naacl-main.83/).

I am extremely fortunate to have been involved in some incredible collaborations. I worked with [Danish](https://www.cs.cmu.edu/~ddanish/) for more than two years to [evaluate explanation methods](https://direct.mit.edu/tacl/article/doi/10.1162/tacl_a_00465/110436/Evaluating-Explanations-How-Much-Do-Explanations) in NLP (started with [a meek awe-inspired email](https://rachitbansal.github.io
/img/danish-email.png)). I also worked for more than two years with [Naomi](https://nsaphra.net/) on studying [mode connectivity in loss surfaces](https://openreview.net/forum?id=hY6M0JHl3uL) of language models (started with [a random message on a Discord channel](https://rachitbansal.github.io
/img/naomi-discord.jpeg)).

I also spent a couple of wonderful summers as a part of the Google Summer of Code program with the Cuneiform Digital Library Initiative ([CDLI](https://cdli.ucla.edu/)). Here, I was advised by [Prof. Jacob Dahl](https://www.wolfson.ox.ac.uk/person/jacob-dahl) and [Dr. Niko Schenk](https://www.english-linguistics.de/nschenk/). My first exposure to research was at [LCS2, IIIT-D](https://www.lcs2.in/).

## <span style="color:darkblue">News and Timeline </span>
**2023**
* **September**  Submitted our work on composing large language models to ICLR 2024.
* **May**  Presenting our linear mode connectivity work at ICLR 2023 (w/ Jeevesh and Naomi) in Kigali, Rwanda!

**2022**
* **September**  My bachelor's thesis work done at the Technion was accepted at NeurIPS 2022!
* **August**  Joining [Google Research India](https://research.google/locations/india/) as a pre-doctoral researcher.
* **June**    Releasing the [pre-print](https://arxiv.org/abs/2205.12411) for our work on analyzing linear mode connectivity of text classifiers with disparate out-of-distribution behaviour. A collaboration with [Dr. Naomi Saphra](http://nsaphra.github.io/) and [Jeevesh Juneja](https://github.com/Jeevesh8).
* **May**     Our work on natural language reasoning while at Adobe MDSR accepted at NAACL 2022. Full papers on commonsense and factual knowledge to be presented at the main conference and findings, respectively.
* **January** Officially starting as a research intern with [Prof. Yonatan Belinkov](http://www.cs.technion.ac.il/~belinkov/) at the Technion, Israel. Characterizing generalization and robustness information-theoretically. 

**2021**
* **November**  After a year-long review and revision process, our work evaluating model explanations has been accepted at TACL. In collaboration with [Danish](https://www.cs.cmu.edu/~ddanish/), and other people from CMU and Google.
* **September** Two full papers with Adobe MDSR accepted at the Workshop on Commonsense Reasoning and Knowledge Bases ([CSKB](https://akbc-cskb.github.io/)) at AKBC 2021.  
<!-- * **July**    Attending [LXMLS 2021](http://lxmls.it.pt/2021/) as a student. -->
<!-- * June 2021:    Volunteering at NAACL 2021. -->
* **May**     Work with CDLI accepted at ACL SRW 2021. Gauging machine translation and sequence labeling for extremely low-resource languages. 
* **May**     Starting as a Research Intern at Adobeâ€™s Media and Data Science Research (MDSR).
<!-- * May 2021:     Volunteering at ICLR 2021. -->
<!-- * **February**  My first research paper accepted at PAKDD 2021. Detecting fake news early, with [Prof. Tanmoy Chakraborty](http://faculty.iiitd.ac.in/~tanmoy/) and [William Scott](https://www.linkedin.com/in/williamscottp/). -->

**2020**
* **November**  Started collaborating with [Danish](https://www.cs.cmu.edu/~ddanish/) (LTI, CMU) on evaluating neural explanations for NLP.
<!-- * Nov 2020:     Volunteering at EMNLP 2020. -->
* **June**    Began contributing to the [Cuneiform Digital Library Initiative](https://cdli.ucla.edu/) (CDLI), University of Oxford. Working on low-resource machine translation.
<!-- * June 2020:    Volunteering at ACL 2020. -->
<!-- * **May**     Joined [LCS2](http://lcs2.iiitd.edu.in/), IIIT-D as a Research Intern. Working on closed-domain misinformation detection across social networks. -->
<!-- * May 2019:     Serving as a Teaching Assistant for the Machine Learning course at Coding Blocks. With [Prateek](http://www.prateeknarang.com/) and [Manu](https://www.manuspillai.in/). -->
